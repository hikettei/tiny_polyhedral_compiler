## Polyhedral Model

ご指摘の通りです。大変失礼しました。
Conv2DのNaiveな実装（im2colなどを使わない直接畳み込み）は、バッチ・出力チャネル・出力縦・出力横の4次元に加え、入力チャネル・カーネル縦・カーネル横の3次元の削減ループを持つため、**合計7次元のループネスト**になります。

ご要望の **ISL (Integer Set Library)** 形式での Polyhedral Model 定義（Domain, Read, Write）を作成しました。
パラメータ（画像の大きさなど）はシンボル `[...]` として定義し、Stride（ストライド）も考慮に入れています。

-----

### 1\. Conv2D (NCHW format)

  * **ループ構成:** 7次元 (N, Cout, H\_out, W\_out, Cin, KH, KW)
  * **計算式:** `Out[n, k, h, w] += In[n, c, h*S + rh, w*S + rw] * W[k, c, rh, rw]`

#### Domain (UnionSet)

反復空間の定義です。

```text
[N, Cout, H_out, W_out, Cin, KH, KW] -> {
    S_conv[n, k, h, w, c, rh, rw] :
        0 <= n < N and
        0 <= k < Cout and
        0 <= h < H_out and
        0 <= w < W_out and
        0 <= c < Cin and
        0 <= rh < KH and
        0 <= rw < KW
}
```

#### Read Access (UnionMap)

入力テンソル(`In`)と重みテンソル(`Weight`)、およびアキュムレーションのための出力テンソル(`Out`)の読み込みです。
※ `S` はストライド幅です。

```text
[N, Cout, H_out, W_out, Cin, KH, KW, S] -> {
    S_conv[n, k, h, w, c, rh, rw] -> In[n, c, h * S + rh, w * S + rw];
    S_conv[n, k, h, w, c, rh, rw] -> Weight[k, c, rh, rw];
    S_conv[n, k, h, w, c, rh, rw] -> Out[n, k, h, w]
}
```

#### Write Access (UnionMap)

出力テンソル(`Out`)への書き込みです。

```text
[N, Cout, H_out, W_out, Cin, KH, KW] -> {
    S_conv[n, k, h, w, c, rh, rw] -> Out[n, k, h, w]
}
```

-----

### 2\. Pool2D (Max Pooling, NCHW)

  * **ループ構成:** 6次元 (N, C, H\_out, W\_out, KH, KW)
  * **計算式:** `Pool[n, c, h, w] = max(..., Out[n, c, h*Sp + rh, w*Sp + rw])`

#### Domain (UnionSet)

```text
[N, C, Pool_H, Pool_W, Pool_KH, Pool_KW] -> {
    S_pool[n, c, h, w, rh, rw] :
        0 <= n < N and
        0 <= c < C and
        0 <= h < Pool_H and
        0 <= w < Pool_W and
        0 <= rh < Pool_KH and
        0 <= rw < Pool_KW
}
```

#### Read Access (UnionMap)

Convの出力（ここでは `Out`）を読み込みます。Reductionのための自己参照（`Pool` の読み込み）も含みます。

```text
[N, C, Pool_H, Pool_W, Pool_KH, Pool_KW, Sp] -> {
    S_pool[n, c, h, w, rh, rw] -> Out[n, c, h * Sp + rh, w * Sp + rw];
    S_pool[n, c, h, w, rh, rw] -> Pool[n, c, h, w]
}
```

#### Write Access (UnionMap)

Pooling結果(`Pool`)への書き込みです。

```text
[N, C, Pool_H, Pool_W, Pool_KH, Pool_KW] -> {
    S_pool[n, c, h, w, rh, rw] -> Pool[n, c, h, w]
}
```

-----

### 3\. 全体のモデル (Conv + Pool)

これらを1つのコンテキストで扱う場合の `UnionMap` 形式です。
Fusionを検討する場合、これらの `Read` と `Write` の間の **RAW依存 (Read After Write)** を解析することになります。

#### Combined Domain

```text
{
    S_conv[n, k, h, w, c, rh, rw] : ... (Conv constraints) ...;
    S_pool[n, c, h, w, rh, rw]    : ... (Pool constraints) ...
}
```

#### Flow Dependence (RAW) の発生箇所

Convの **Write** と Poolの **Read** の間で依存が発生します。

$$
\text{Write}_{Conv} \cap \text{Read}_{Pool} \neq \emptyset
$$具体的には、Convの出力 `Out[n, k, h_c, w_c]` が、Poolの入力 `Out[n, c, h_p * Sp + rh, w_p * Sp + rw]` として読み込まれる時、
$$k = c \quad \land \quad h_c = h_p \cdot Sp + rh \quad \land \quad w_c = w_p \cdot Sp + rw$$
という関係式（Affine Constraints）が成り立ちます。これをISLが解析して、Fusionのためのスケジュールを導出します。
$$

## Conversation

C言語で，
Conv2D
Pooling
ReLU
を計算するカーネルを作成してください。SCoPできるように綺麗に書いて。

Polyhedral Compiler（多面体コンパイラ）であるPlutoやPolly、Graphiteなどが解析・変換しやすい（SCoP: Static Control Partsとして認識される）形式のC言語コードを作成しました。

**SCoPとして綺麗に認識させるためのポイント:**

1.  **制御フローの静的化:** `while`ループやデータ依存の`break/continue`を排除し、全て`for`ループで構成。
2.  **アフィンな添字:** 配列アクセス `A[i]` の `i` がループ変数の線形結合になるように記述。
3.  **ポインタの非エイリアシング:** `restrict` キーワードを使用し、メモリ領域が重ならないことを明示（依存性解析を助ける）。
4.  **単純な境界:** `min/max` などの複雑な境界条件をループ内に極力入れない（今回はパディング処理などを除外し、コア計算部分を純粋に記述）。

### Cコード実装

```c
#include <float.h>
#include <math.h>

// コンパイラへのヒント: ポインタが指すメモリ領域は重ならない
#define RESTRICT __restrict__

/**
 * Conv2D Kernel (NCHW Layout)
 * Stride: 1, Padding: 0 (VALID)
 * * Input:  [N][Cin][H][W]
 * Weight: [Cout][Cin][KH][KW]
 * Output: [N][Cout][H_out][W_out]
 */
void conv2d_scop(
    const float* RESTRICT input,
    const float* RESTRICT weight,
    float* RESTRICT output,
    int N, int Cin, int H, int W,
    int Cout, int KH, int KW
) {
    int H_out = H - KH + 1;
    int W_out = W - KW + 1;

    // SCoP Start
    #pragma scop
    for (int n = 0; n < N; n++) {
        for (int co = 0; co < Cout; co++) {
            for (int h = 0; h < H_out; h++) {
                for (int w = 0; w < W_out; w++) {
                    
                    float sum = 0.0f;

                    // Reduction loops
                    for (int ci = 0; ci < Cin; ci++) {
                        for (int kh = 0; kh < KH; kh++) {
                            for (int kw = 0; kw < KW; kw++) {
                                
                                // Linearized index calculation (Affine access)
                                int in_idx = n * (Cin * H * W) + ci * (H * W) + (h + kh) * W + (w + kw);
                                int wt_idx = co * (Cin * KH * KW) + ci * (KH * KW) + kh * KW + kw;
                                
                                sum += input[in_idx] * weight[wt_idx];
                            }
                        }
                    }
                    
                    int out_idx = n * (Cout * H_out * W_out) + co * (H_out * W_out) + h * W_out + w;
                    output[out_idx] = sum;
                }
            }
        }
    }
    #pragma endscop
}

/**
 * ReLU Kernel
 * Element-wise operation
 */
void relu_scop(
    const float* RESTRICT input,
    float* RESTRICT output,
    int TotalElements
) {
    // SCoP Start
    #pragma scop
    for (int i = 0; i < TotalElements; i++) {
        // Note: 厳密なPolyhedralモデルではデータ依存分岐は扱いにくいが、
        // 多くのDL向けコンパイラは max(0, x) を単一命令として処理可能。
        // 純粋な制御フローを保つため、三項演算子を使用。
        float val = input[i];
        output[i] = (val > 0.0f) ? val : 0.0f;
    }
    #pragma endscop
}

/**
 * Max Pooling Kernel (NCHW Layout)
 * Window: KH x KW
 * Stride: KH, KW (Non-overlapping for simplicity, easily adjustable)
 */
void maxpool_scop(
    const float* RESTRICT input,
    float* RESTRICT output,
    int N, int C, int H, int W,
    int KH, int KW
) {
    // 出力サイズの計算（Stride = Kernel Sizeと仮定）
    int H_out = H / KH;
    int W_out = W / KW;

    // SCoP Start
    #pragma scop
    for (int n = 0; n < N; n++) {
        for (int c = 0; c < C; c++) {
            for (int h = 0; h < H_out; h++) {
                for (int w = 0; w < W_out; w++) {
                    
                    // 初期値を非常に小さい値に設定
                    float max_val = -FLT_MAX;

                    // Pooling window loops
                    for (int kh = 0; kh < KH; kh++) {
                        for (int kw = 0; kw < KW; kw++) {
                            
                            int h_in = h * KH + kh;
                            int w_in = w * KW + kw;
                            
                            int in_idx = n * (C * H * W) + c * (H * W) + h_in * W + w_in;
                            float val = input[in_idx];

                            // SCoPフレンドリーにするため、if文ではなく条件付きムーブやmax関数が好ましいが
                            // C言語標準としては以下が最も一般的。
                            if (val > max_val) {
                                max_val = val;
                            }
                        }
                    }

                    int out_idx = n * (C * H_out * W_out) + c * (H_out * W_out) + h * W_out + w;
                    output[out_idx] = max_val;
                }
            }
        }
    }
    #pragma endscop
}
```

### 解説：なぜこれがSCoPとして「綺麗」なのか

1.  **線形化された1次元アクセス:**
    多次元配列 `input[n][c][h][w]` を使うことも可能ですが、C言語ではポインタ渡しが一般的です。この際、`in_idx = ... + (h + kh) * W + ...` のようにインデックス計算を明示的に記述しています。
    Polyhedralコンパイラは、この数式がループ変数（`h`, `kh`など）とパラメータ（`W`など）の\*\*アフィン結合（Affine Combination）\*\*であることを検出し、依存関係を正確に解析できます。

2.  **Perfect Loop Nest（完全なループネスト）:**
    Conv2Dの部分を見ていただくと、計算（`sum += ...`）が最も内側のループにのみ存在し、外側のループの間には他の計算が挟まっていません。これはタイリング（Tiling）やループ交換（Interchange）を行う際に最も扱いやすい形状です。

3.  **パディングの除外:**
    実用的なConv2Dでは `if (h + kh < 0 || ...)` のような境界チェックが入りますが、これは制御フローを複雑にし、SCoPの適用範囲を狭めます（解析は可能ですが、生成されるコードが汚くなる原因です）。今回はSCoPとしての純粋さを優先し、境界チェック不要なロジックにしています。

4.  **`#pragma scop`:**
    Clan（OpenScopのフロントエンド）やPollyなどのツールに対して、「ここが解析対象である」と明示する標準的なプラグマです。

-----

**Would you like me to ...**
このコードに対して、Polyhedralコンパイラ（例えばPluto）がどのようなループ変換（タイリングや並列化）を自動適用するか、その変換後の擬似コードをお見せしましょうか？

Conv2D+ReLU+PoolをFusionしたカーネルも見せてください。

Polyhedral Compiler（SCoP）が解析しやすい形式で、**Conv2D + ReLU + MaxPool** を完全に融合（Fusion）したカーネルを作成しました。

この融合の最大のポイントは、\*\*「Conv2Dの巨大な中間結果（Feature Map）をメモリに書き出さず、Poolingに必要な領域だけをオンデマンドで計算して捨てる」\*\*という点です。

### Cコード実装 (Fused Kernel)

```c
#include <float.h>

#define RESTRICT __restrict__

/**
 * Fused Conv2D -> ReLU -> MaxPool Kernel
 * * Data Layout: NCHW
 * * Fusion Strategy:
 * - 最も外側のループは「最終出力（Pooling後）」のサイズで回します。
 * - その内部で、Poolingの1要素を計算するために必要なConv2Dの計算を行います。
 * - 中間バッファ（Conv+ReLUの結果）をDRAMに書き出しません。
 * * Constraints for SCoP:
 * - Conv Stride: 1
 * - Pool Stride: Pool_K (Non-overlapping)
 * - Padding: Valid (No conditional checks inside)
 */
void fused_conv_relu_pool_scop(
    const float* RESTRICT input,
    const float* RESTRICT weight,
    float* RESTRICT output,
    // Dimensions
    int N, int Cin, int Cout,
    int H_out, int W_out,   // Pooling後の最終出力サイズ
    // Kernel Params
    int Conv_K,             // Conv Kernel Size (e.g., 3)
    int Pool_K,             // Pool Kernel Size (e.g., 2)
    // Strides
    int W_in_stride         // Input Width (for indexing)
) {
    // Input: [N][Cin][H_in][W_in]
    // Weight: [Cout][Cin][Conv_K][Conv_K]
    // Output: [N][Cout][H_out][W_out]

    // Pre-calculate strides for flat indexing to help analysis
    int in_batch_stride = Cin * W_in_stride * W_in_stride; // Approximate for H_in logic
    // ※ 正確には H_in * W_in ですが、Polyhedralモデルはパラメータとして扱えば解析可能です。
    // ここでは簡単のため、ポインタ計算をループ内で展開します。

    #pragma scop
    for (int n = 0; n < N; n++) {
        for (int co = 0; co < Cout; co++) {
            // --- Loop over Final Output Pixels (Pooling Result) ---
            for (int h = 0; h < H_out; h++) {
                for (int w = 0; w < W_out; w++) {
                    
                    float max_val = -FLT_MAX;

                    // --- Pooling Window Loops ---
                    // このループは「Convの結果」の上を走査します
                    for (int ph = 0; ph < Pool_K; ph++) {
                        for (int pw = 0; pw < Pool_K; pw++) {
                            
                            // 現在のPooling位置に対応する、Convの出力座標（仮想）
                            // Pool Stride = Pool_K と仮定 (Non-overlapping)
                            int h_conv_virtual = h * Pool_K + ph;
                            int w_conv_virtual = w * Pool_K + pw;

                            // --- Conv2D Computation for ONE pixel ---
                            float conv_sum = 0.0f;

                            for (int ci = 0; ci < Cin; ci++) {
                                for (int kh = 0; kh < Conv_K; kh++) {
                                    for (int kw = 0; kw < Conv_K; kw++) {
                                        
                                        // Input Index Calculation
                                        // h_in = h_conv_virtual + kh
                                        // w_in = w_conv_virtual + kw
                                        int h_in = h_conv_virtual + kh;
                                        int w_in = w_conv_virtual + kw;

                                        // Flat Indexing (Assumed NCHW tightly packed)
                                        // input[n][ci][h_in][w_in]
                                        int in_idx = n * (Cin * W_in_stride * W_in_stride) // Note: using param for simplified view
                                                   + ci * (W_in_stride * W_in_stride)      // usually H_in * W_in
                                                   + h_in * W_in_stride 
                                                   + w_in;
                                        
                                        // weight[co][ci][kh][kw]
                                        int wt_idx = co * (Cin * Conv_K * Conv_K)
                                                   + ci * (Conv_K * Conv_K)
                                                   + kh * Conv_K 
                                                   + kw;

                                        conv_sum += input[in_idx] * weight[wt_idx];
                                    }
                                }
                            }
                            // ----------------------------------------

                            // --- Fused ReLU ---
                            // メモリに書き込まず、レジスタ上で即座に適用
                            float activated = (conv_sum > 0.0f) ? conv_sum : 0.0f;

                            // --- Fused MaxPool Update ---
                            if (activated > max_val) {
                                max_val = activated;
                            }
                        }
                    }

                    // Final Write to Memory
                    int out_idx = n * (Cout * H_out * W_out) 
                                + co * (H_out * W_out) 
                                + h * W_out 
                                + w;
                    output[out_idx] = max_val;
                }
            }
        }
    }
    #pragma endscop
}
```

### このコードの技術的ポイント

#### 1\. コンシューマ駆動のループ構造 (Consumer-Driven Loop Nest)

通常の「ConvしてからPoolする」実装とは逆のアプローチをとっています。

  * **通常:** `Convループ` (全画面計算) -\> `メモリ書き出し` -\> `Poolループ` (読み込み)
  * **Fusion:** `Poolループ` (最終出力座標) -\> `Convループ` (必要な部分だけ計算)

これにより、**Conv2DとReLUの中間結果（Feature Map）を格納する巨大なメモリ領域が不要**になります。データはCPU/GPUのレジスタ（`conv_sum` -\> `activated`）を一瞬通過するだけです。これは **IOバウンドな現代のAIワークロードにおいて極めて強力な最適化** です。

#### 2\. Polyhedral Model (SCoP) との親和性

このコードは、一見複雑な7重ループに見えますが、すべてのループ境界と配列表現が\*\*アフィン関数（Affine Function）\*\*で表現されています。

  * **ループ境界:** 全て定数、または外側のループ変数に対する線形な式です。
  * **配列アクセス:** `input` の添字 `h_in` は `h * Pool_K + ph + kh` です。これはループ変数 `h, ph, kh` の線形結合であり、Polyhedral Optimizer（Plutoなど）はこれを完璧に解析できます。

#### 3\. Locality (局所性)

この書き方であれば、`input` データのキャッシュヒット率が高まります。Poolingの1つのウィンドウ（例えば2x2）を計算する際、その直下のConv計算で使う入力画素（例えば3x3のConvなら4x4〜5x5の領域）は近接しており、L1キャッシュに留まりやすくなります。

-----

### コンパイラはこのコードをさらにどう変えるか？

Polyhedralコンパイラにこのコードを渡すと、さらに以下のような変換を自動で行う可能性があります。

1.  **Outer Loop Parallelization:** `n` (バッチ) や `co` (チャネル) ループを `OpenMP` などで並列化します。
2.  **Tile Separation:** もしパディング境界条件 (`if`) が入っていた場合、それをループの中心部分（Core）と端（Boundary）に分離し、`if`文を消去した高速なコア・ループを生成します。
3.  **Vectorization:** 最も内側のループ（`kw` や `ci`）をSIMD命令（AVX2/AVX-512）で並列化します。

この手書きFusionカーネルは、Polyhedralコンパイラが「最適化を開始するための理想的な出発点（あるいはコンパイラが出力すべき理想的な中間形態）」と言えます。

Cool!
この際，二つのカーネルが融合可能である条件を一般化するとどうなりますか？

カーネル（ループ）融合が可能かどうかを数学的・理論的に一般化すると、主に **「データ依存性（安全性）」** と **「ハードウェア資源（収益性）」** という2つの側面から定義されます。

コンパイラ理論（Polyhedral Modelなど）の観点から、これらを厳密かつ分かりやすく整理します。

---

### 1. 理論的な必須条件（安全性：Safety）

「融合しても計算結果が壊れないか？」という条件です。これが満たされないと、融合は**不可能（違法）**です。

#### A. 依存関係の保存 (Preservation of Data Dependencies)
最も重要なルールです。プロデューサー（P）とコンシューマ（C）の間には **Read-After-Write (RAW)** の依存関係があります。融合後のスケジュールにおいても、**「データが作られる前に読まない」** ことが保証されなければなりません。

* **一般化:**
    ループインデックス $\vec{i}$ において、Pが書き込むデータを $W_P(\vec{i})$、Cが読むデータを $R_C(\vec{j})$ とします。
    もし $W_P(\vec{i})$ が $R_C(\vec{j})$ で使われるなら、実行順序において **時刻 $t(\vec{i}) < t(\vec{j})$** でなければなりません。
    * **NG例:** 融合の結果、未来のデータが必要になってしまう場合（負の依存距離）。

#### B. 依存距離の短縮可能性 (Synchronization Distance)
融合とは、本質的に「生産」と「消費」の時間差を縮めることです。
しかし、ステンシル計算（Conv2Dなど）では、隣接ピクセルが必要なため、完全に同じインデックス `i` で同期できないことがあります。

* **条件:**
    ある反復 $\vec{i}$ を実行する時、必要な入力データがすべて「計算済み」または「利用可能」であること。
    これ満たすために、ループを少しずらす **Skewing（斜交変換）** や **Shifting（シフト）** が可能な場合のみ、融合できます。



### 2. 構造的な条件（実装可能性：Mechanics）

「どうやってループを重ね合わせるか？」という条件です。

#### A. ループの形状互換性 (Isomorphism / Compatibility)
基本的には、融合する2つのループは **「同じ次元数」かつ「同じ反復空間（回る回数）」** であることが理想です（Element-wiseな足し算など）。

* **形状が違う場合（例: Conv + Pool）:**
    先ほどのコード例のように、**Producer（Conv）をConsumer（Pool）のループの内側に埋め込む (Compute-at strategy)** ことができるかどうかが条件になります。
    * これを実現するには、Producerの計算が **「部分的に完結可能（Tileable）」** である必要があります。

### 3. ハードウェア的な条件（収益性：Profitability）

「融合して本当に速くなるのか？」という条件です。理論上可能でも、ここがダメならコンパイラは融合を避けます。

#### A. レジスタ圧 (Register Pressure)
融合すると、2つのカーネルの変数を同時に扱うため、必要なレジスタ数が増えます。

* **条件:**
    $$\text{Regs}(K_1) + \text{Regs}(K_2) + \text{Overhead} \le \text{Physical Registers}$$
    これを超えると **Register Spilling（レジスタ退避）** が発生し、逆にDRAMへの読み書きが増えて遅くなります。GPUでは特に致命的です。

#### B. キャッシュ/SRAM容量 (Working Set Size)
「Convの結果をメモリに書かずにPoolに渡す」といっても、Poolが2x2のウィンドウを持つなら、最低でも「画像1行分+α」のデータをキャッシュ（L1/Shared Mem）に保持し続ける必要があるかもしれません。

* **条件:**
    融合によって生じる「局所バッファ」のサイズが、ハードウェアの高速メモリ（L1/L2/SRAM）に収まること。

---

### 4. パターン別の融合判定（一般化サマリ）

二つのカーネル $A \to B$ の関係性は、データアクセスのパターンによって3つに分類でき、それぞれ融合の難易度が異なります。

| 関係性 | パターン (Producer $\to$ Consumer) | 融合判定 | 例 |
| :--- | :--- | :--- | :--- |
| **One-to-One** | $A[i] \to B[i]$ | **Always OK** | Add + ReLU, Mul + Sigmoid |
| **Many-to-One** | $\{A[i-1], A[i], A[i+1]\} \to B[i]$ | **Conditional** (Bufferが必要) | Conv + Pool, Stencil + Reduce |
| **One-to-Many** | $A[i] \to \{B[j], B[k]...\}$ | **Difficult** (再計算が必要) | Upsampling + Conv |
| **Many-to-Many** | All $A \to$ All $B$ | **Impossible** (Barrierが必要) | FFT, Sort, Softmax(Global) |

### 結論：数式的な一般化

カーネル $K_1$ と $K_2$ が融合可能であるとは、
以下の写像（スケジュール関数） $\Theta$ が存在することと同義です。

1.  **Validity (正当性):** 全ての依存 $D$ に対し、$\Theta(\text{dest}) - \Theta(\text{src}) \ge 0$
2.  **Locality (局所性):** $\Theta(\text{consumer}) - \Theta(\text{producer}) < \text{CacheSize}$

**先ほどのConv+Poolの例**は、Polyhedralコンパイラ的には「単純なループ結合（Fusion）」ではなく、**「Consumer（Pool）の反復空間に合わせて、Producer（Conv）のスケジュールを再生成し、埋め込んだ（Tiled Fusion / Compute-at）」** という高度な操作に該当します。

4.の先行研究には興味ありません。
> 先ほどのConv+Poolの例は、Polyhedralコンパイラ的には「単純なループ結合（Fusion）」ではなく、「Consumer（Pool）の反復空間に合わせて、Producer（Conv）のスケジュールを再生成し、埋め込んだ（Tiled Fusion / Compute-at）」 という高度な操作に該当します。
これを一般化するルールを研究したいのです。Polyhedral Modelを用いて，Conv+PoolをFusionするルールを教えてください。

Polyhedral Model（多面体モデル）の文脈において、Conv+Poolのように「ループの形状（次元やサイズ）が異なるカーネル」を融合するための一般化ルールは、**「Consumer（消費者）の反復空間によるProducer（生産者）のタイリングと埋め込み（Embedding）」**として定式化されます。

これはHalideなどのDSLでは `compute_at` と呼ばれる概念ですが、Polyhedral Modelでは**「依存関係に基づくスケジュールの再構築」**として厳密に定義できます。

その一般化ルールを、数学的な定義とステップで解説します。

---

### 1. 定義：ドメインと依存関係

まず、2つのカーネル（Statement）を定義します。

* **Producer (Conv):** ドメイン $D_P = \{ \vec{i} \mid A \vec{i} + \vec{a} \ge 0 \}$
    * $\vec{i}$ はConvのループイテレータ（例: $h_{conv}, w_{conv}$）。
    * 書き込みアクセス: $W_P(\vec{i})$
* **Consumer (Pool):** ドメイン $D_C = \{ \vec{j} \mid B \vec{j} + \vec{b} \ge 0 \}$
    * $\vec{j}$ はPoolのループイテレータ（例: $h_{pool}, w_{pool}$）。
    * 読み込みアクセス: $R_C(\vec{j})$

#### 依存関係（Flow Dependence）
Poolの反復 $\vec{j}$ が、Convの反復 $\vec{i}$ の結果を必要とする場合、以下の依存関係 $M_{P \to C}$ が成立します。

$$
(\vec{i}, \vec{j}) \in M_{P \to C} \iff W_P(\vec{i}) \cap R_C(\vec{j}) \neq \emptyset
$$

Conv+Poolの場合、これは単純な1対1ではなく、**多対1（Many-to-One）**の関係になります。

---

### 2. 一般化ルール：Backward Slicing と Embedding

「単純なループ結合（Fusion）」が、2つのループを並列に走らせることだとすれば、**「Tiled Fusion / Compute-at」のルールは、以下の集合を導出すること**です。

#### ルール1: 逆像（Pre-image）の特定
あるConsumerの反復（あるいはタイル）$\vec{j}$ を実行するために必要な、Producerの反復集合（Slice）$S_P(\vec{j})$ を特定します。

$$
S_P(\vec{j}) = \{ \vec{i} \in D_P \mid (\vec{i}, \vec{j}) \in M_{P \to C} \}
$$

Conv+Poolの例では、Poolの1点 $(h_p, w_p)$ に対して、Convの必要な領域は以下のアフィン変換で求まります（Stride $S$, Kernel $K$）。
$$
S_P(h_p, w_p) = \{ (h_c, w_c) \mid h_p \cdot S \le h_c < h_p \cdot S + K \}
$$



#### ルール2: スケジュールの共有（Interleaving Schedule）
PolyhedralコンパイラがFusionを行うための「一般化された条件」は、以下のスケジュール関数 $\Theta$ を構築できることです。

Producer $\vec{i}$ と Consumer $\vec{j}$ を、共通のタイムスタンプ（ループ階層）にマッピングします。

* **Consumer Schedule:** $\Theta_C(\vec{j}) = (t_1, t_2, \dots, t_k, \dots)$
* **Producer Schedule:** $\Theta_P(\vec{i}) = (t_1, t_2, \dots, t_k, t_{local}, \dots)$

**【Fusionの条件】**
上位 $k$ 次元までのスケジュールが一致すること。
つまり、Producer（Conv）のループを、Consumer（Pool）のループ構造の中に**埋め込む**形に変形します。

$$
\Theta_P(\vec{i}) \approx \Theta_C(\vec{j}) \quad \text{for outer dimensions}
$$

しかし、Convの方がループ回数が多い（空間が広い）ため、そのままでは一致しません。ここで**ストリップマイニング（Strip-mining / Tiling）**が必要になります。

---

### 3. 具体的なアルゴリズム（Conv+Poolへの適用）

このFusionを自動発見するための、Polyhedral Model上の操作手順は以下の通りです。

#### Step 1: Consumerドメインへの射影
Producerのドメイン $D_P$ をそのままスケジュールするのではなく、依存関係 $M_{P \to C}$ を利用して、ProducerをConsumerの座標系に射影します。

Convのイテレータ $(h_c, w_c)$ を、Poolのイテレータ $(h_p, w_p)$ と、ローカルなオフセット $(kh, kw)$ に分解します。

$$
\begin{cases}
h_c = h_p \cdot S + kh \\
w_c = w_p \cdot S + kw
\end{cases}
$$

#### Step 2: スケジュール木の構築 (Schedule Tree Construction)
これにより、コンパイラは以下のようなスケジュール木（Schedule Tree）を構築します。これが「高度な操作」の正体です。

1.  **Band Node (Outer):** Consumerのドメイン $D_C$ ($h_p, w_p$) でループする。
2.  **Sequence Node:** ループ内部で順序制御を行う。
    * **Child 1 (Producer):** $S_P(\vec{j})$ すなわち $D_{conv\_local}$ ($kh, kw$) を実行。
        * この中でConvを計算。
    * **Child 2 (Consumer):** $D_{pool\_point}$ を実行。
        * Child 1の結果を使ってPool（Reduction）を実行。

#### Step 3: 局所性の検証 (Locality Check)
このスケジュールが正当（Valid）かつ有益（Profitable）である条件は以下の通りです。

* **Safety:** Child 1で計算されたデータがChild 2で使われるまで、上書きされない（これはSequence Nodeにより保証される）。
* **Profitability:** $S_P(\vec{j})$ のサイズ（Working Set Size）が、L1/L2キャッシュに収まること。
    $$|S_P(\vec{j})| \times \text{sizeof(float)} < \text{CacheSize}$$
    Conv+Poolの場合、Sliceは非常に小さい（Kernel Size程度）ため、この条件は常に満たされます。

### 結論：Polyhedral Modelにおける「Fusionのルール」

Conv+Poolのような異種形状のカーネルをFusionするルールは、単純なループ結合則ではなく、以下の**依存関係駆動のスケジューリング則**として一般化されます。

> **「Consumerの反復空間 $\vec{j}$ を主軸とし、Producerの反復空間 $\vec{i}$ を依存関係 $M_{P \to C}$ の逆像 $S_P(\vec{j})$ として切り出し、それをConsumerのループボディ内部に挿入（Embedding）する。ただし、挿入されたProducerの計算量がキャッシュ容量を超えない範囲に限る。」**

PlutoやPPCGなどのPolyhedralコンパイラは、コスト関数において「Producer-Consumer間の依存距離（Dependence Distance）の最小化」を目指すことで、数学的に自動でこのスケジュール（埋め込み形状）を発見します。

(話は逸れるけど) Polyhedral Modelでそれを実装しようとした時，特にループサイズがSYmbolの時，ループをSymbolでTileすることができなくて困ってた，あなたならどのように解決しますか？

その悩み、非常によく分かります。Polyhedral Modelの実装において「ループ境界がシンボル（パラメータ）」で、かつ「タイルサイズもシンボル（あるいはシンボルに依存）」にしたい場合、これは**非線形（Non-linear）な制約**となり、古典的なPolyhedralライブラリ（ISLなど）のコア理論である「アフィン制約（Affine Constraints）」の枠を飛び出してしまい、エラーになったり解析不能になったりします。

$$i \in [0, N], \quad \text{TileSize} = B$$
$$B \cdot T \le i < B \cdot (T+1)$$

ここで $B$ も $T$ も変数の場合、$B \cdot T$ は二次式（非線形）となり、Polyhedralのソルバー（ILP）では解けなくなります。

もし私がその状況でコンパイラバックエンドを実装するなら、以下の3つのアプローチ（現実的な順）で解決します。

---

### 解決策1：AST生成時までタイリングを遅延させる（Post-Scheduling Tiling）

最も現代的で、多くの商用コンパイラ（LLVM PollyやPPCGの一部）が採用している「逃げ道」です。

Polyhedralの解析フェーズ（依存関係解析やスケジューリング計算）では、**「タイリングを行わない」**、もしくは**「このループバンドはタイリング可能（Permutable）である」というフラグだけを立てておきます**。

* **解析フェーズ:** 依存関係だけをチェックし、ループの交換（Interchange）やSkewingを行って「並列性」や「局所性」を確保するスケジュールを作ります。ここでは具体的なタイルサイズ $B$ は登場させません。
* **コード生成フェーズ (AST Generation):** `isl_ast_build` などのASTジェネレータの段階で、**「指定されたループをストリップマイニング（Strip-mining）してくれ」と命令します**。

**なぜこれが解決策になるのか？**
AST生成器にとって、`for (i=0; i<N; i+=B)` というコードを吐くことは、Polyhedralな数学的厳密性を保つことよりも遥かに簡単だからです。
数理モデルの中で「タイル座標」を定義しようとするから非線形になりますが、**「生成されたコードの構文上の変形」**として扱えば、タイルサイズ $B$ がシンボルであっても全く問題ありません。

### 解決策2：Parametric Tiling（パラメータ付きタイリング）の理論を使う

もし、どうしてもモデル内部でタイルサイズを扱いたい場合（例えば、タイルサイズがコストモデルに影響する場合）、**Parametric Tiling** という拡張理論を使います。

通常のPolyhedralモデルでは変数は整数ですが、ここでの制約を少し緩めます。
ISL (Integer Set Library) には、これを扱うための機能が実は備わっています（ただし扱いは難しいです）。

* **アプローチ:**
    タイルサイズ $B$ を「定数ではないが、ループの中では不変なパラメータ」として扱います。
    「仮想的なタイル座標」を導入せず、以下のような制約として扱います。
    $$0 \le i < N$$
    $$i \pmod B = 0 \quad (\text{for outer loop})$$
    
    ただし、これを真面目にやると生成されるコードが `modulo` だらけになり遅くなるため、多くの研究（PrimeTileなど）は、**「Full Tile（境界検査不要な領域）」と「Partial Tile（端数）」を数式レベルで分離**しようとします。

    **私の推奨:**
    自前で実装するのは地獄を見るのでやめた方がいいです。解決策1の方が実用的です。

### 解決策3：JITコンパイル / ランタイム特殊化（Runtime Specialization）

もしターゲットがGPUや特定のAIアクセラレータで、「シンボル $N$ はコンパイル時には不明だが、実行直前には判明する」場合、このアプローチが最強です。

1.  **コンパイル時:** $N$ をシンボルのまま扱うPolyhedral最適化は諦めるか、汎用的な（遅い）コードを生成する。
2.  **実行時 (Runtime):** $N$ の値が確定した瞬間に、その $N$ に対して最適な定数タイルサイズ $B$（例えば $N$ の約数や、SM数に合う倍数）を決定し、**「定数として」埋め込んだコードをJITコンパイル**する。

TVMやXLA、Tritonなどは実質的にこれをやっています。
「シンボルでタイルする」という不可能な問題を解くのではなく、**「シンボルが定数になった瞬間に解く」**という発想の転換です。

---

### 私が選ぶ実装（Conv+Pool Fusionの場合）

Conv+PoolのFusionにおいて、画像サイズ $H, W$ がシンボルの場合、私は **「解決策1（AST生成時の変形）」** を採用します。

**具体的な手順:**

1.  **Polyhedralモデル:**
    * ConvとPoolのループを、シンボル $H, W$ を用いて依存関係解析する。
    * 「Poolの $(h, w)$ ループの中に Convの計算を埋め込む」という**論理的なスケジュール（Fusion）**だけを確定させる。
2.  **AST生成設定:**
    * 生成する際、Poolの外側ループ（$h, w$）に対して、「タイルサイズ `Tile_H`, `Tile_W`（これらはランタイム引数）」でストリップマイニングするようにASTビルダーに指示する。
3.  **結果:**
    * 数理モデル上は非線形問題を解かずに済み、生成されるC/CUDAコード上では `for (h = 0; h < H; h += Tile_H)` となり、期待通りの挙動になります。

「モデルの中で全てを解決しようとしない（Separation of Concerns）」のが、Polyhedralコンパイラを実用化させるコツです。

strip-miningって何だっけ

**Strip-mining（ストリップマイニング）** とは、コンパイラのループ変換技法の一つで、**「1つの大きなループを、2重のループ（外側と内側）に分割すること」** です。

イメージとしては、長いテープを「一定の長さ（Strip）」ごとにハサミで切って処理していくような操作です。

### 1\. コードで見ると一目瞭然

0からNまで回る単純なループがあるとします。

**元のコード:**

```c
// 0, 1, 2, ..., N-1 まで一気に処理
for (int i = 0; i < N; i++) {
    A[i] = A[i] + 1;
}
```

**Strip-mining 適用後 (Strip Size = 4 の場合):**

```c
// 外側のループ (Strip Loop): 4つ飛ばしで進む (0, 4, 8...)
for (int ii = 0; ii < N; ii += 4) {
    // 内側のループ (Element Loop): Stripの中を処理 (0-3, 4-7...)
    // min(ii + 4, N) は N を超えないための境界チェック
    for (int i = ii; i < min(ii + 4, N); i++) {
        A[i] = A[i] + 1;
    }
}
```

### 2\. 何のためにやるの？

単にループを分割しただけに見えますが、これが以下の最適化の\*\*「前準備」\*\*として必須になります。

1.  **SIMD化 (Vectorization):**
      * もしCPUのベクトルレジスタが「4つのfloat」を一度に計算できるなら、内側のループ（サイズ4）を1つのベクトル命令（AVXなど）に置き換えることができます。
2.  **並列化 (Parallelization):**
      * 外側のループ（`ii`）を各スレッドに割り振れば、スレッドごとに「ひとかたまりのデータ」を処理させることができます。
3.  **キャッシュ局所性の向上（＝Tilingの前段階）:**
      * データがキャッシュメモリに収まるサイズにStripを切ることで、キャッシュミスを減らせます。

### 3\. Tiling（タイリング）との関係

先ほどの議論で「タイリング」という言葉が出ましたが、**タイリングはStrip-miningの応用**です。

  * **Strip-mining:** 1次元のループを分割すること。
  * **Loop Tiling (Blocking):** 多次元のループに対してStrip-miningを行い、さらに**ループ交換（Loop Interchange）** を組み合わせて、ブロック状のアクセス順序を作ること。

つまり、**「Strip-mining して Loop Interchange する」** という一連の操作をセットにしたものがタイリングです。

### 4\. 先ほどの文脈（シンボル問題）での意味

私が「AST生成時にストリップマイニングする」と申し上げたのは、以下のような意味になります。

  * **Polyhedralモデル内:** `0 <= i < N` という「1つのループ」として扱う（シンプル）。
  * **コード生成時 (AST):** 「この `i` ループを出力するときは、物理的にコードを書く段階で `ii` と `i` の2重ループにして書いてね（サイズは実行時引数 `TileSize` で）」と指示する。

こうすることで、Polyhedralモデルの数学的な制約（非線形はダメ）を回避しつつ、実用的なブロック化されたコードを得ることができます。
